{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Use pretrained ResNet cnn to predict concentration plot over 6-minute sampling\n",
    "### Firstly, import dependencies"
   ],
   "id": "3efbaa87fbf7c4e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:25.198934Z",
     "start_time": "2024-08-21T23:04:23.740005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ],
   "id": "1e9608c34e204461",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7743efdd9090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Then, we import the pre-fine-tuned model (a .pth file), and pass it to gpu memory.",
   "id": "60ab05c460807568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:27.722852Z",
     "start_time": "2024-08-21T23:04:26.834616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 2)  # 假设有2个分类\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('best_alexnet.pth'))\n",
    "model.eval()\n",
    "model.cuda()                                                    # pass the model to cuda                                                 # test the model-loading condition"
   ],
   "id": "ef9abf7f7c020ce6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybercricetus/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cybercricetus/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### We define some pre-process transformation for the test images.",
   "id": "1be602f50f13c88c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:29.073789Z",
     "start_time": "2024-08-21T23:04:29.070443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224), transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224), transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}           # ResNet only support 224*224 images, resize to avoid losing information"
   ],
   "id": "d7b97f29ac235660",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define device variable (optional)",
   "id": "1130a006a60a8585"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:30.699728Z",
     "start_time": "2024-08-21T23:04:30.697590Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
   "id": "fdd6e005b20f6a3e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define directory and classes",
   "id": "37638877f201a17f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:31.705031Z",
     "start_time": "2024-08-21T23:04:31.703075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_dir = \"tests\"\n",
    "_classes = ['near', 'far']\n",
    "pic_name_list = _1st_dir = os.listdir(_dir)"
   ],
   "id": "205ed93390c34d0e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Traverse through the directory, read the images to CPU buffer and then GPU buffer, and finally do prediction with model loaded in GPU memory",
   "id": "cd058d4064a32647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:33.309665Z",
     "start_time": "2024-08-21T23:04:32.826131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = 0                                               # correct counts\n",
    "result_cmp_set = {}                                     # actual:pred\n",
    "for name in pic_name_list:                              # traverse the directory\n",
    "    img = Image.open(_dir+'/'+name).convert('RGB')      # open the image\n",
    "    img = data_transforms['val'](img)                   # do the transformation\n",
    "    img = img.unsqueeze(0)                      \n",
    "    img = img.to(device)                                # pass to GPU memory\n",
    "\n",
    "    with torch.no_grad():           \n",
    "        outputs = model(img)                            # predict\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    result_cmp_set[name] = _classes[preds]              # add prediction to the collection\n",
    "    if _classes[preds][0] == name[1]:                   # if correctly predicted, count+1\n",
    "        count += 1"
   ],
   "id": "fbf7672aa4885314",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check the result ",
   "id": "3b351f506d7e730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T23:04:34.267406Z",
     "start_time": "2024-08-21T23:04:34.265132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result_cmp_set)                                 \n",
    "print('accuracy is: ', count / len(pic_name_list))   # accuracy\n",
    "print(\"Correct count = \", count)\n",
    "print(\"Incorrect count = \", len(pic_name_list)-count)"
   ],
   "id": "13532040201f5240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_far6.png': 'far', '_near3.png': 'near', '_far5.png': 'far', '_far2.png': 'far', '_far8.png': 'far', '_far3.png': 'far', '_near6.png': 'near', '_far9.png': 'far', '_near9.png': 'near', '_near7.png': 'near', '_far10.png': 'far', '_far7.png': 'far', '_near2.png': 'near', '_far4.png': 'far', '_near4.png': 'far', '_near5.png': 'near', '_near8.png': 'near', '_far1.png': 'far', '_near1.png': 'near', '_near10.png': 'far'}\n",
      "accuracy is:  0.9\n",
      "Correct count =  18\n",
      "Incorrect count =  2\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "71eb361f18b5aeda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
