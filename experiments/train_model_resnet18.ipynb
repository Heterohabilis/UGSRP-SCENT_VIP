{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Collision Avoidance - Train Model (ResNet18)\n\nWelcome to this host side Jupyter Notebook!  This should look familiar if you ran through the notebooks that run on the robot.  In this notebook we'll train our image classifier to detect two classes\n``free`` and ``blocked``, which we'll use for avoiding collisions.  For this, we'll use a popular deep learning library *PyTorch*"
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:34:40.417975Z",
     "start_time": "2024-07-18T19:34:40.415776Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Upload and extract dataset\n\nBefore you start, you should upload the ``dataset.zip`` file that you created in the ``data_collection.ipynb`` notebook on the robot.\n\nYou should then extract this dataset by calling the command below"
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:34:41.291101Z",
     "start_time": "2024-07-18T19:34:41.111256Z"
    }
   },
   "source": "!unzip -q dataset.zip",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open dataset.zip, dataset.zip.zip or dataset.zip.ZIP.\r\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "You should see a folder named ``dataset`` appear in the file browser."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Create dataset instance"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now we use the ``ImageFolder`` dataset class available with the ``torchvision.datasets`` package.  We attach transforms from the ``torchvision.transforms`` package to prepare the data for training.  "
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:36:37.937568Z",
     "start_time": "2024-07-18T19:36:37.934429Z"
    }
   },
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'concen_graph',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Split dataset into train and test sets"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Next, we split the dataset into *training* and *test* sets.  The test set will be used to verify the accuracy of the model we train."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:34:43.558658Z",
     "start_time": "2024-07-18T19:34:43.556595Z"
    }
   },
   "source": "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Create data loaders to load data in batches"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We'll create two ``DataLoader`` instances, which provide utilities for shuffling data, producing *batches* of images, and loading the samples in parallel with multiple workers."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:37:24.220729Z",
     "start_time": "2024-07-18T19:37:24.191033Z"
    }
   },
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset)\n\u001B[0;32m----> 2\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\n\u001B[1;32m      3\u001B[0m     train_dataset,\n\u001B[1;32m      4\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m      5\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m     num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      9\u001B[0m test_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\n\u001B[1;32m     10\u001B[0m     test_dataset,\n\u001B[1;32m     11\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m     12\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     13\u001B[0m     num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     14\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:350\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[0;32m--> 350\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m RandomSampler(dataset, generator\u001B[38;5;241m=\u001B[39mgenerator)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    352\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/sampler.py:143\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[0;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Define the neural network\n\nNow, we define the neural network we'll be training.  The *torchvision* package provides a collection of pre-trained models that we can use.\n\nIn a process called *transfer learning*, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n\nImportant features that were learned in the original training of the pre-trained model are re-usable for the new task.  We'll use the ``resnet18`` model."
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:32:51.931863Z",
     "start_time": "2024-07-18T19:32:51.829342Z"
    }
   },
   "source": "model = models.resnet18(pretrained=True)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybercricetus/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cybercricetus/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The ``resnet18`` model was originally trained for a dataset that had 1000 class labels, but our dataset only has two class labels!  We'll replace\nthe final layer with a new, untrained layer that has only two outputs.  "
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:32:54.137181Z",
     "start_time": "2024-07-18T19:32:54.134445Z"
    }
   },
   "source": "model.fc = torch.nn.Linear(512, 2)",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Finally, we transfer our model for execution on the GPU"
  },
  {
   "cell_type": "code",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:32:57.856911Z",
     "start_time": "2024-07-18T19:32:55.739545Z"
    }
   },
   "source": "device = torch.device('cuda')\nmodel = model.to(device)",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Train the neural network\n\nUsing the code below we will train the neural network for 30 epochs, saving the best performing model after each epoch.\n\n> An epoch is a full run through our data."
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T19:32:59.030234Z",
     "start_time": "2024-07-18T19:32:59.011103Z"
    }
   },
   "source": [
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'fine_tuned_models/best_model_resnet18.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy >= best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 9\u001B[0m\n\u001B[1;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mSGD(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(NUM_EPOCHS):\n\u001B[0;32m----> 9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(train_loader):\n\u001B[1;32m     10\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     11\u001B[0m         labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Once that is finished, you should see a file ``best_model_resnet18.pth`` in the Jupyter Lab file browser.  Select ``Right click`` -> ``Download`` to download the model to your workstation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
